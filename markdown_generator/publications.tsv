order	pub_date	title	venue	excerpt	citation	url_slug	paper_url	ccfrank
1	2024-11-04	CHIME: A Cache-Efficient and High-Performance Hybrid Index on Disaggregated Memory	SOSP	"Disaggregated memory (DM) is a widely discussed datacenter architecture in academia and industry. It decouples computing and memory resources from monolithic servers into two network-connected resource pools. Range indexes are widely adopted by storage systems on DM to efficiently locate and query remote data. However, existing range indexes on DM suffer from either high computing-side cache consumption or high memory-side read amplifications. In this paper, we propose <strong>CHIME</strong>, a hybrid index combining B+ trees with hopscotch hashing, to achieve low cache consumption and low read amplifications simultaneously. There are three challenges in constructing CHIME on DM, i.e., the complicated optimistic synchronization, the extra metadata access, and the read amplifications introduced by hopscotch hashing. CHIME leverages 1) a three-level optimistic synchronization scheme to synchronize read and write operations with various granularities, 2) an access-aggregated metadata management technique to eliminate extra metadata accesses by piggybacking and replicating metadata, and 3) an effective hotness-aware speculative read mechanism to mitigate the read amplifications of hopscotch hashing. Experimental results show that CHIME outperforms the state-of-the-art range indexes on DM by up to 5.1x with the same cache size and achieves similar performance with up to 8.7x lower cache consumption."	"Xuchuan Luo, et al. ""CHIME: A Cache-Efficient and High-Performance Hybrid Index on Disaggregated Memory"" 30th ACM Symposium on Operating Systems Principles (SOSP). 2024."	CHIME	https://doi.org/10.1145/3694715.3695959	CCF A
2	2023-07-11	SMART: A High-Performance Adaptive Radix Tree for Disaggregated Memory	OSDI	"Disaggregated memory (DM) is an increasingly prevalent architecture in academia and industry with high resource utilization. It separates computing and memory resources into two pools and interconnects them with fast networks. Existing range indexes on DM are based on B+ trees, which suffer from large inherent read and write amplifications. The read and write amplifications rapidly saturate the network bandwidth, resulting in low request throughput and high access latency of B+ trees on DM.

In this paper, we propose to use the radix tree, which is more suitable for DM than the B+ tree due to smaller read and write amplifications. However, constructing a radix tree on DM is challenging due to the costly lock-based concurrency control, the bounded memory-side IOPS, and the complicated computing-side cache validation. To address these challenges, we design <strong>SMART</strong>, the first radix tree for disaggregated memory with high performance. Specifically, we leverage 1) a hybrid concurrency control scheme including lock-free internal nodes and fine-grained lock-based leaf nodes to reduce lock overhead, 2) a computing-side read-delegation and write-combining technique to break through the IOPS upper bound by reducing redundant I/Os, and 3) a simple yet effective reverse check mechanism for computing-side cache validation. Experimental results show that SMART achieves 6.1x higher throughput under typical write-intensive workloads and 2.8x higher throughput under read-only workloads, compared with state-of-the-art B+ trees on DM."	"Xuchuan Luo, et al. ""SMART: A High-Performance Adaptive Radix Tree for Disaggregated Memory."" 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI). 2023."	SMART	https://www.usenix.org/system/files/osdi23-luo.pdf	CCF A
3	2024-05-08	A Memory-Disaggregated Radix Tree	TOS	"Disaggregated memory (DM) is an increasingly prevalent architecture with high resource utilization. It separates computing and memory resources into two pools and interconnects them with fast networks. Existing range indexes on DM are based on B+ trees, which suffer from large inherent read and write amplifications. The read and write amplifications rapidly saturate the network bandwidth, resulting in low request throughput and high access latency of B+ trees on DM.

In this article, we propose that the radix tree is more suitable for DM than the B+ tree due to smaller read and write amplifications. However, constructing a radix tree on DM is challenging due to the costly lock-based concurrency control, the bounded memory-side IOPS, and the complicated computing-side cache validation. To address these challenges, we design <strong>SMART</strong>, the first radix tree for disaggregated memory with high performance. Specifically, we leverage (1) a hybrid concurrency control scheme including lock-free internal nodes and fine-grained lock-based leaf nodes to reduce lock overhead, (2) a computing-side read-delegation and write-combining technique to break through the IOPS upper bound by reducing redundant I/Os, and (3) a simple yet effective reverse check mechanism for computing-side cache validation. Experimental results show that SMART achieves 6.1x higher throughput under typical write-intensive workloads and 2.8x higher throughput under read-only workloads in YCSB benchmarks, compared with state-of-the-art B+ trees on DM."	"Xuchuan Luo, et al. ""A Memory-Disaggregated Radix Tree."" ACM Transactions on Storage (TOS). 2024."	SMART-TOS	https://dl.acm.org/doi/10.1145/3664289	CCF A
4	2023-10-23	Ditto: An Elastic and Adaptive Memory-Disaggregated Caching System	SOSP	"In-memory caching systems are fundamental building blocks in cloud services. However, due to the coupled CPU and memory on monolithic servers, existing caching systems cannot elastically adjust resources in a resource-efficient and agile manner. To achieve better elasticity, we propose to port in-memory caching systems to the disaggregated memory (DM) architecture, where compute and memory resources are decoupled and can be allocated flexibly. However, constructing an elastic caching system on DM is challenging since accessing cached objects with CPU-bypass remote memory accesses hinders the execution of caching algorithms. Moreover, the elastic changes of compute and memory resources on DM affect the access patterns of cached data, compromising the hit rates of caching algorithms. We design <strong>Ditto</strong>, the first caching system on DM, to address these challenges. Ditto first proposes a client-centric caching framework to efficiently execute various caching algorithms in the compute pool of DM, relying only on remote memory accesses. Then, Ditto employs a distributed adaptive caching scheme that adaptively switches to the best-fit caching algorithm in real-time based on the performance of multiple caching algorithms to improve cache hit rates. Our experiments show that Ditto effectively adapts to the changing resources on DM and outperforms the state-of-the-art caching systems by up to 3.6x in real-world workloads and 9x in YCSB benchmarks."	"Jiacheng Shen, et al. ""Ditto: An Elastic and Adaptive Memory-Disaggregated Caching System"" 29th ACM Symposium on Operating Systems Principles (SOSP). 2023."	Ditto	https://dl.acm.org/doi/10.1145/3600006.3613144	CCF A
5	2023-02-21	FUSEE: A Fully Memory-Disaggregated Key-Value Store	FAST	"Distributed in-memory key-value (KV) stores are embracing the disaggregated memory (DM) architecture for higher resource utilization. However, existing KV stores on DM employ a semi-disaggregated design that stores KV pairs on DM but manages metadata with monolithic metadata servers, hence still suffering from low resource efficiency on metadata servers. To address this issue, this paper proposes <strong>FUSEE</strong>, a fully memory-disaggregated KV store that brings disaggregation to metadata management. FUSEE replicates metadata, i.e., the index and memory management information, on memory nodes, manages them directly on the client side, and handles complex failures under the DM architecture. To scalably replicate the index on clients, FUSEE proposes a client-centric replication protocol that allows clients to concurrently access and modify the replicated index. To efficiently manage disaggregated memory, FUSEE adopts a two-level memory management scheme that splits the memory management duty among clients and memory nodes. Finally, to handle the metadata corruption under client failures, FUSEE leverages an embedded operation log scheme to repair metadata with low log maintenance overhead. We evaluate FUSEE with both micro and YCSB hybrid benchmarks. The experimental results show that FUSEE outperforms the state-of-the-art KV stores on DM by up to 4.5 times with less resource consumption."	"Jiacheng Shen, et al. ""FUSEE: A Fully Memory-Disaggregated Key-Value Store."" 21st USENIX Conference on File and Storage Technologies (FAST). 2023."	FUSEE	https://www.usenix.org/system/files/fast23-shen.pdf	CCF A
6	2022-05-10	Muffin: Testing Deep Learning Libraries via Neural Architecture Fuzzing	ICSE	"Deep learning (DL) techniques are proven effective in many challenging tasks, and become widely-adopted in practice. However, previous work has shown that DL libraries, the basis of building and executing DL models, contain bugs and can cause severe consequences. Unfortunately, existing testing approaches still cannot comprehensively exercise DL libraries. They utilize existing trained models and only detect bugs in model inference phase. In this work we propose <strong>Muffin</strong> to address these issues. To this end, Muffin applies a specifically-designed model fuzzing approach, which allows it to generate diverse DL models to explore the target library, instead of relying only on existing trained models. Muffin makes differential testing feasible in the model training phase by tailoring a set of metrics to measure the inconsistencies between different DL libraries. In this way, Muffin can best exercise the library code to detect more bugs. To evaluate the effectiveness of Muffin, we conduct experiments on three widely-used DL libraries. The results demonstrate that Muffin can detect 39 new bugs in the latest release versions of popular DL libraries, including Tensorflow, CNTK, and Theano."	"Jiazhen Gu, et al. ""Muffin: Testing Deep Learning Libraries via Neural Architecture Fuzzing."" Proceedings of the 44th International Conference on Software Engineering (ICSE). 2022."	Muffin	https://dl.acm.org/doi/10.1145/3510003.3510092	CCF A
